{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a1a15",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d71621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/Coursera.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} courses\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48809f",
   "metadata": {},
   "source": [
    "## 2. Clean Course Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(text):\n",
    "    \"\"\"\n",
    "    Clean course description text:\n",
    "    - Remove HTML tags\n",
    "    - Remove special characters and weird encodings\n",
    "    - Normalize whitespace\n",
    "    - Remove URLs\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Fix common encoding issues (ï¿½)\n",
    "    text = text.replace('ï¿½', \"'\")\n",
    "    text = text.replace('â€™', \"'\")\n",
    "    text = text.replace('â€œ', '\"')\n",
    "    text = text.replace('â€', '\"')\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the function\n",
    "sample_text = df['Course Description'].iloc[0]\n",
    "print(\"Original:\")\n",
    "print(sample_text[:200])\n",
    "print(\"\\nCleaned:\")\n",
    "print(clean_description(sample_text)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to all descriptions\n",
    "print(\"Cleaning course descriptions...\")\n",
    "df['Course Description Clean'] = df['Course Description'].apply(clean_description)\n",
    "\n",
    "# Show improvement\n",
    "print(f\"\\nOriginal avg length: {df['Course Description'].str.len().mean():.0f} chars\")\n",
    "print(f\"Cleaned avg length: {df['Course Description Clean'].str.len().mean():.0f} chars\")\n",
    "print(f\"Empty descriptions: {(df['Course Description Clean'] == '').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ee404",
   "metadata": {},
   "source": [
    "## 3. Clean Skills Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ea853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_skills(skills_str):\n",
    "    \"\"\"\n",
    "    Parse and clean skills string:\n",
    "    - Split by multiple spaces (delimiter in dataset)\n",
    "    - Remove duplicates\n",
    "    - Remove empty/invalid entries\n",
    "    - Standardize capitalization\n",
    "    \"\"\"\n",
    "    if pd.isna(skills_str) or not isinstance(skills_str, str):\n",
    "        return []\n",
    "    \n",
    "    # Split by multiple spaces\n",
    "    skills = [s.strip() for s in skills_str.split('  ')]\n",
    "    \n",
    "    # Filter out empty and very short entries\n",
    "    skills = [s for s in skills if s and len(s) > 1]\n",
    "    \n",
    "    # Remove duplicates (case-insensitive)\n",
    "    seen = set()\n",
    "    unique_skills = []\n",
    "    for skill in skills:\n",
    "        skill_lower = skill.lower()\n",
    "        if skill_lower not in seen:\n",
    "            seen.add(skill_lower)\n",
    "            unique_skills.append(skill)\n",
    "    \n",
    "    return unique_skills\n",
    "\n",
    "# Test the function\n",
    "sample_skills = df['Skills'].iloc[0]\n",
    "print(\"Original:\")\n",
    "print(sample_skills)\n",
    "print(\"\\nCleaned:\")\n",
    "print(clean_skills(sample_skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcedebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply skill cleaning\n",
    "print(\"Cleaning skills data...\")\n",
    "df['Skills Clean'] = df['Skills'].apply(clean_skills)\n",
    "df['Skills Count'] = df['Skills Clean'].apply(len)\n",
    "\n",
    "print(f\"\\nSkill statistics:\")\n",
    "print(f\"  Courses with skills: {(df['Skills Count'] > 0).sum():,}\")\n",
    "print(f\"  Courses without skills: {(df['Skills Count'] == 0).sum():,}\")\n",
    "print(f\"  Avg skills per course: {df['Skills Count'].mean():.1f}\")\n",
    "print(f\"  Max skills per course: {df['Skills Count'].max()}\")\n",
    "print(f\"  Min skills per course: {df['Skills Count'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda5162",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in key columns\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df[['Course Name', 'University', 'Course Rating', 'Difficulty Level']].isnull().sum())\n",
    "\n",
    "# Fill missing ratings with 0.0\n",
    "df['Course Rating'] = df['Course Rating'].fillna(0.0)\n",
    "\n",
    "# Fill missing difficulty with 'Intermediate'\n",
    "df['Difficulty Level'] = df['Difficulty Level'].fillna('Intermediate')\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df[['Course Name', 'University', 'Course Rating', 'Difficulty Level']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34454603",
   "metadata": {},
   "source": [
    "## 5. Create Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final cleaned dataset\n",
    "df_clean = df[[\n",
    "    'Course Name',\n",
    "    'University',\n",
    "    'Difficulty Level',\n",
    "    'Course Rating',\n",
    "    'Course URL',\n",
    "    'Course Description Clean',\n",
    "    'Skills Clean'\n",
    "]].copy()\n",
    "\n",
    "# Rename columns\n",
    "df_clean.columns = [\n",
    "    'course_name',\n",
    "    'university',\n",
    "    'difficulty',\n",
    "    'rating',\n",
    "    'url',\n",
    "    'description',\n",
    "    'skills'\n",
    "]\n",
    "\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cb2a0",
   "metadata": {},
   "source": [
    "## 6. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89aaa019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report:\n",
      "============================================================\n",
      "Duplicate course names: 106\n",
      "\n",
      "Description lengths:\n",
      "  Avg: 1145 chars\n",
      "  Min: 4 chars\n",
      "  Max: 8547 chars\n",
      "  Empty: 0\n",
      "\n",
      "Rating distribution:\n",
      "  Mean: 4.55\n",
      "  Median: 4.60\n",
      "  Std: 0.34\n",
      "\n",
      "Difficulty distribution:\n",
      "difficulty\n",
      "Beginner          1444\n",
      "Advanced          1005\n",
      "Intermediate       837\n",
      "Conversant         186\n",
      "Not Calibrated      50\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Quality Report:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for duplicate course names\n",
    "duplicates = df_clean['course_name'].duplicated().sum()\n",
    "print(f\"Duplicate course names: {duplicates}\")\n",
    "\n",
    "# Check description lengths\n",
    "desc_lengths = df_clean['description'].str.len()\n",
    "print(f\"\\nDescription lengths:\")\n",
    "print(f\"  Avg: {desc_lengths.mean():.0f} chars\")\n",
    "print(f\"  Min: {desc_lengths.min()} chars\")\n",
    "print(f\"  Max: {desc_lengths.max()} chars\")\n",
    "print(f\"  Empty: {(desc_lengths == 0).sum()}\")\n",
    "\n",
    "# Convert rating to numeric for statistics\n",
    "df_clean['rating'] = pd.to_numeric(df_clean['rating'], errors='coerce')\n",
    "\n",
    "# Check rating distribution\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(f\"  Mean: {df_clean['rating'].mean():.2f}\")\n",
    "print(f\"  Median: {df_clean['rating'].median():.2f}\")\n",
    "print(f\"  Std: {df_clean['rating'].std():.2f}\")\n",
    "\n",
    "# Check difficulty distribution\n",
    "print(f\"\\nDifficulty distribution:\")\n",
    "print(df_clean['difficulty'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a000e",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5868d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned data saved to: ..\\data\\processed\\coursera_cleaned.csv\n",
      "✓ Total courses saved: 3,522\n",
      "✓ Cleaned data (with list format) saved to: ..\\data\\processed\\coursera_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save cleaned data\n",
    "output_path = output_dir / 'coursera_cleaned.csv'\n",
    "\n",
    "# Convert skills list to string for CSV export\n",
    "df_export = df_clean.copy()\n",
    "df_export['skills'] = df_export['skills'].apply(lambda x: '  '.join(x) if x else '')\n",
    "\n",
    "df_export.to_csv(output_path, index=False)\n",
    "print(f\"✓ Cleaned data saved to: {output_path}\")\n",
    "print(f\"✓ Total courses saved: {len(df_export):,}\")\n",
    "\n",
    "# Also save as pickle to preserve list format\n",
    "pickle_path = output_dir / 'coursera_cleaned.pkl'\n",
    "df_clean.to_pickle(pickle_path)\n",
    "print(f\"✓ Cleaned data (with list format) saved to: {pickle_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff52ea3",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1233701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING SUMMARY\n",
      "================================================================================\n",
      "Input: 3,522 courses\n",
      "Output: 3,522 courses\n",
      "\n",
      "Cleaning operations performed:\n",
      "  ✓ Cleaned course descriptions (removed HTML, fixed encoding)\n",
      "  ✓ Parsed and deduplicated skills\n",
      "  ✓ Handled missing values\n",
      "  ✓ Standardized column names\n",
      "\n",
      "Output files:\n",
      "  ✓ ..\\data\\processed\\coursera_cleaned.csv\n",
      "  ✓ ..\\data\\processed\\coursera_cleaned.pkl\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input: {len(df):,} courses\")\n",
    "print(f\"Output: {len(df_clean):,} courses\")\n",
    "print(f\"\\nCleaning operations performed:\")\n",
    "print(\"  ✓ Cleaned course descriptions (removed HTML, fixed encoding)\")\n",
    "print(\"  ✓ Parsed and deduplicated skills\")\n",
    "print(\"  ✓ Handled missing values\")\n",
    "print(\"  ✓ Standardized column names\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  ✓ {output_path}\")\n",
    "print(f\"  ✓ {pickle_path}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "up knowledge graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
